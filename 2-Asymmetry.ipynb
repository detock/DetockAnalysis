{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T23:53:20.739470Z",
     "iopub.status.busy": "2021-12-10T23:53:20.739161Z",
     "iopub.status.idle": "2021-12-10T23:53:26.714859Z",
     "shell.execute_reply": "2021-12-10T23:53:26.714016Z",
     "shell.execute_reply.started": "2021-12-10T23:53:20.739416Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .config(\"spark.driver.memory\", \"16g\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T23:53:26.716222Z",
     "iopub.status.busy": "2021-12-10T23:53:26.715994Z",
     "iopub.status.idle": "2021-12-10T23:53:27.525230Z",
     "shell.execute_reply": "2021-12-10T23:53:27.524234Z",
     "shell.execute_reply.started": "2021-12-10T23:53:26.716201Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T00:35:46.473296Z",
     "iopub.status.busy": "2021-12-11T00:35:46.473019Z",
     "iopub.status.idle": "2021-12-11T00:35:46.784419Z",
     "shell.execute_reply": "2021-12-11T00:35:46.783491Z",
     "shell.execute_reply.started": "2021-12-11T00:35:46.473276Z"
    }
   },
   "outputs": [],
   "source": [
    "PREFIX = \"main/ycsb-asym\"\n",
    "\n",
    "IGNORE_CACHE = False\n",
    "\n",
    "index_df = from_cache_or_compute(\n",
    "    f'{PREFIX}/index.parquet',\n",
    "    lambda: get_index(spark, PREFIX)\\\n",
    "        .withColumn(\"asym_ratio\", F.regexp_extract(\"prefix\", r\"asym_ratio(\\d+)\", 1))\\\n",
    "        .withColumn(\"config_name\", F.regexp_replace(\"config_name\", \"\\.conf\", \"\"))\\\n",
    "        .toPandas()\\\n",
    "        .convert_dtypes()\\\n",
    "        .astype({\n",
    "            \"wl:hot\": \"int32\",\n",
    "            \"wl:mh\": \"int32\",\n",
    "            \"wl:mp\": \"int32\",\n",
    "        }),\n",
    "    ignore_cache=IGNORE_CACHE,\n",
    ")\n",
    "\n",
    "index_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T00:36:37.971854Z",
     "iopub.status.busy": "2021-12-11T00:36:37.971594Z",
     "iopub.status.idle": "2021-12-11T00:36:46.938710Z",
     "shell.execute_reply": "2021-12-11T00:36:46.937589Z",
     "shell.execute_reply.started": "2021-12-11T00:36:37.971833Z"
    }
   },
   "outputs": [],
   "source": [
    "IGNORE_CACHE = False\n",
    "\n",
    "def compute_throughput(prefix):\n",
    "    res = throughput(\n",
    "        spark,\n",
    "        prefix,\n",
    "        start_offset_sec=10,\n",
    "        duration_sec=50\n",
    "    ).first().throughput\n",
    "    print(prefix, res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_all_throughputs(index_df):\n",
    "    # Extract all prefixes in the index\n",
    "    throughput_df = index_df.loc[:, [\"prefix\"]]\n",
    "    # Compute the throughput of each prefix\n",
    "    throughput_df[\"throughput\"] = throughput_df.apply(lambda r : compute_throughput(r[\"prefix\"]), axis=1)\n",
    "    # Associate metadata from the index to the throughputs\n",
    "    return throughput_df.merge(index_df, on=\"prefix\")\n",
    "\n",
    "\n",
    "throughput_df = from_cache_or_compute(\n",
    "    f'{PREFIX}/throughput.parquet',\n",
    "    lambda: compute_all_throughputs(index_df[index_df[\"clients\"] == 3000])\\\n",
    "        .sort_values(\"asym_ratio\"),\n",
    "    ignore_cache=IGNORE_CACHE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T00:37:07.089374Z",
     "iopub.status.busy": "2021-12-11T00:37:07.089103Z",
     "iopub.status.idle": "2021-12-11T00:37:09.349109Z",
     "shell.execute_reply": "2021-12-11T00:37:09.348336Z",
     "shell.execute_reply.started": "2021-12-11T00:37:07.089354Z"
    }
   },
   "outputs": [],
   "source": [
    "IGNORE_CACHE = False\n",
    "\n",
    "percentile_cols = [\n",
    "    F.percentile_approx(\"latency\", 0.5).alias(\"p50\"),\n",
    "    F.percentile_approx(\"latency\", 0.90).alias(\"p90\"),\n",
    "    F.percentile_approx(\"latency\", 0.95).alias(\"p95\"),\n",
    "    F.percentile_approx(\"latency\", 0.99).alias(\"p99\"),\n",
    "]\n",
    "\n",
    "latency_df = from_cache_or_compute(\n",
    "    f'{PREFIX}/latency.parquet',\n",
    "    lambda:  latency(\n",
    "        spark,\n",
    "        index_df.loc[index_df[\"clients\"] == 200, \"prefix\"]\n",
    "    )\\\n",
    "        .groupBy(\"prefix\")\\\n",
    "        .agg(*percentile_cols)\\\n",
    "        .toPandas()\\\n",
    "        .merge(index_df, on=\"prefix\")\\\n",
    "        .sort_values(\"asym_ratio\"),\n",
    "    ignore_cache=IGNORE_CACHE,\n",
    ")\n",
    "\n",
    "latency_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-11T00:19:18.952333Z",
     "iopub.status.busy": "2021-12-11T00:19:18.952048Z",
     "iopub.status.idle": "2021-12-11T00:19:19.123772Z",
     "shell.execute_reply": "2021-12-11T00:19:19.122932Z",
     "shell.execute_reply.started": "2021-12-11T00:19:18.952314Z"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "throughput_df.plot.bar(ax=ax, x=\"asym_ratio\", y=\"throughput\", rot=0, fill=False, hatch='/')\n",
    "ax.set_ylabel(\"throughput (txn/s)\")\n",
    "ax.set_xlabel(\"asymmetry ratio\")\n",
    "ax.legend(loc=\"lower left\")\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "latency_df.plot(ax=ax2, x=\"asym_ratio\", y=\"p50\", label='p50 latency', linestyle='dotted', marker='.', color=\"red\")\n",
    "latency_df.plot(ax=ax2, x=\"asym_ratio\", y=\"p90\", label='p90 latency', linestyle='dashed', marker='.', color=\"red\")\n",
    "latency_df.plot(ax=ax2, x=\"asym_ratio\", y=\"p99\", label='p99 latency', marker='.', color=\"red\")\n",
    "ax2.set_ylabel(\"latency (ms)\")\n",
    "ax2.set_ylim((0, 350))\n",
    "ax2.set_xticklabels([\"50:50\", \"60:40\", \"70:30\", \"80:20\", \"90:10\"])\n",
    "\n",
    "ax2.legend(loc=\"lower right\", ncol=1)\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/asymmetry.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6d70b928e3b547af58be583a486d1526112f45e5dbd54efba8c49d7a2e37afa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
